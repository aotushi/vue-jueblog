# Day 21: æ•°æ®å¯¼å…¥åˆ° D1 åŠŸèƒ½

> ğŸ“… **æ—¥æœŸ**ï¼š**\_**  
> â° **è®¡åˆ’æ—¶é•¿**ï¼š1å°æ—¶  
> â±ï¸ **å®é™…æ—¶é•¿**ï¼š**\_**  
> ğŸ“Š **å®Œæˆåº¦**ï¼š\_\_\_\_%

## ğŸ¯ ä»Šæ—¥ä»»åŠ¡

- [ ] å®ç° D1 æ•°æ®åº“æ‰¹é‡å¯¼å…¥åŠŸèƒ½
- [ ] å¤„ç†äº‹åŠ¡å’Œé”™è¯¯å›æ»šæœºåˆ¶
- [ ] åˆ›å»ºæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å·¥å…·
- [ ] æµ‹è¯•å®Œæ•´çš„è¿ç§»æµç¨‹

## ğŸ“š å­¦ä¹ ç¬”è®°

### Cloudflare D1 æ‰¹é‡å¯¼å…¥ç­–ç•¥

#### D1 æ•°æ®åº“ç‰¹æ€§å’Œé™åˆ¶

```
Cloudflare D1 ç‰¹æ€§:
â”œâ”€â”€ åŸºäº SQLite 3.x
â”œâ”€â”€ åˆ†å¸ƒå¼è¾¹ç¼˜å­˜å‚¨
â”œâ”€â”€ æ”¯æŒæ ‡å‡† SQL è¯­æ³•
â”œâ”€â”€ å†…ç½®äº‹åŠ¡æ”¯æŒ
â”œâ”€â”€ ACID å…¼å®¹æ€§ä¿è¯
â””â”€â”€ å…¨çƒè¾¹ç¼˜å¤åˆ¶

æ“ä½œé™åˆ¶:
â”œâ”€â”€ å•æ¬¡æŸ¥è¯¢æœ€å¤§ 25MB
â”œâ”€â”€ äº‹åŠ¡è¶…æ—¶ 30 ç§’
â”œâ”€â”€ å¹¶å‘è¿æ¥é™åˆ¶
â”œâ”€â”€ æ‰¹é‡æ“ä½œå»ºè®® <1000 æ¡
â””â”€â”€ å†™å…¥é¢‘ç‡é™åˆ¶
```

#### æ‰¹é‡å¯¼å…¥æ¶æ„è®¾è®¡

```
æ•°æ®å¯¼å…¥æµæ°´çº¿:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON æ•°æ®æ–‡ä»¶   â”‚â”€â”€â”€â–¶â”‚ æ•°æ®é¢„å¤„ç†      â”‚â”€â”€â”€â–¶â”‚ æ‰¹é‡å†™å…¥ D1     â”‚
â”‚ - users.json    â”‚    â”‚ - æ•°æ®éªŒè¯      â”‚    â”‚ - äº‹åŠ¡ç®¡ç†      â”‚
â”‚ - articles.json â”‚    â”‚ - æ ¼å¼è½¬æ¢      â”‚    â”‚ - é”™è¯¯å¤„ç†      â”‚
â”‚ - comments.json â”‚    â”‚ - ä¾èµ–æ’åº      â”‚    â”‚ - è¿›åº¦è·Ÿè¸ª      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®å¯¼å…¥æµç¨‹è®¾è®¡

#### å¯¼å…¥é¡ºåºå’Œä¾èµ–å…³ç³»

```typescript
// æ•°æ®å¯¼å…¥å¿…é¡»æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œ
const IMPORT_ORDER = [
  'users', // 1. ç”¨æˆ·è¡¨ï¼ˆæ— ä¾èµ–ï¼‰
  'articles', // 2. æ–‡ç« è¡¨ï¼ˆä¾èµ–ç”¨æˆ·ï¼‰
  'article_tags', // 3. æ ‡ç­¾è¡¨ï¼ˆä¾èµ–æ–‡ç« ï¼‰
  'comments', // 4. è¯„è®ºè¡¨ï¼ˆä¾èµ–ç”¨æˆ·ã€æ–‡ç« ï¼‰
  'praises', // 5. ç‚¹èµè¡¨ï¼ˆä¾èµ–ç”¨æˆ·ã€æ–‡ç« ã€è¯„è®ºï¼‰
  'user_stats', // 6. ç»Ÿè®¡è¡¨ï¼ˆä¾èµ–ç”¨æˆ·ï¼‰
]
```

## ğŸ› ï¸ å®è·µæ“ä½œ

### æ­¥éª¤1ï¼šå®ç° D1 æ•°æ®å¯¼å…¥å™¨

```typescript
// src/import.ts
import Database from 'better-sqlite3'
import { readFileSync } from 'fs'
import { join } from 'path'
import chalk from 'chalk'
import dotenv from 'dotenv'

dotenv.config()

interface ImportStats {
  tables: Record<string, number>
  totalRecords: number
  totalTime: number
  errors: string[]
}

interface ImportResult {
  success: boolean
  stats: ImportStats
  message: string
}

class D1Importer {
  private db: Database.Database
  private batchSize: number = 500

  constructor(private dbPath: string) {
    this.db = new Database(dbPath)
    this.db.pragma('journal_mode = WAL') // ä¼˜åŒ–å¹¶å‘æ€§èƒ½
    this.db.pragma('synchronous = NORMAL') // å¹³è¡¡å®‰å…¨å’Œæ€§èƒ½
  }

  async importAll(): Promise<ImportResult> {
    console.log(chalk.blue('ğŸš€ å¼€å§‹æ•°æ®å¯¼å…¥åˆ° D1...'))

    const startTime = Date.now()
    const stats: ImportStats = {
      tables: {},
      totalRecords: 0,
      totalTime: 0,
      errors: [],
    }

    try {
      // 1. é¦–å…ˆåˆ›å»ºè¡¨ç»“æ„
      await this.createTables()

      // 2. æŒ‰ä¾èµ–é¡ºåºå¯¼å…¥æ•°æ®
      const importOrder = [
        { file: 'users.json', table: 'users' },
        { file: 'articles.json', table: 'articles' },
        { file: 'article_tags.json', table: 'article_tags' },
        { file: 'comments.json', table: 'comments' },
      ]

      for (const { file, table } of importOrder) {
        console.log(chalk.yellow(`ğŸ“¥ å¯¼å…¥ ${table} æ•°æ®...`))

        const count = await this.importTable(file, table)
        stats.tables[table] = count
        stats.totalRecords += count

        console.log(chalk.green(`âœ“ ${table} å¯¼å…¥å®Œæˆ: ${count} æ¡è®°å½•`))
      }

      // 3. åˆ›å»ºç´¢å¼•ï¼ˆåœ¨æ•°æ®å¯¼å…¥ååˆ›å»ºï¼Œæé«˜å¯¼å…¥é€Ÿåº¦ï¼‰
      await this.createIndexes()

      // 4. éªŒè¯æ•°æ®å®Œæ•´æ€§
      await this.validateImport()

      stats.totalTime = Date.now() - startTime

      console.log(chalk.blue('\\nğŸ“Š å¯¼å…¥ç»Ÿè®¡:'))
      Object.entries(stats.tables).forEach(([table, count]) => {
        console.log(chalk.white(`  ${table}: ${count} æ¡`))
      })
      console.log(chalk.white(`  æ€»è®°å½•æ•°: ${stats.totalRecords}`))
      console.log(
        chalk.white(`  ç”¨æ—¶: ${(stats.totalTime / 1000).toFixed(2)} ç§’`),
      )

      console.log(chalk.green('\\nğŸ‰ æ•°æ®å¯¼å…¥æˆåŠŸå®Œæˆï¼'))

      return {
        success: true,
        stats,
        message: 'æ•°æ®å¯¼å…¥å®Œæˆ',
      }
    } catch (error) {
      stats.errors.push(error.message)
      console.error(chalk.red('âŒ æ•°æ®å¯¼å…¥å¤±è´¥:'), error)

      return {
        success: false,
        stats,
        message: `å¯¼å…¥å¤±è´¥: ${error.message}`,
      }
    } finally {
      this.db.close()
    }
  }

  private async createTables(): Promise<void> {
    console.log(chalk.yellow('ğŸ—ï¸  åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„...'))

    const schema = `
      -- ç”¨æˆ·è¡¨
      CREATE TABLE IF NOT EXISTS users (
        id TEXT PRIMARY KEY,
        phone TEXT UNIQUE NOT NULL,
        username TEXT NOT NULL,
        password TEXT NOT NULL,
        avatar TEXT DEFAULT '',
        introduc TEXT DEFAULT '',
        position TEXT DEFAULT '',
        company TEXT DEFAULT '',
        location TEXT DEFAULT '',
        website TEXT DEFAULT '',
        github TEXT DEFAULT '',
        jue_power INTEGER DEFAULT 0,
        good_num INTEGER DEFAULT 0,
        read_num INTEGER DEFAULT 0,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
      );
      
      -- æ–‡ç« è¡¨
      CREATE TABLE IF NOT EXISTS articles (
        id TEXT PRIMARY KEY,
        title TEXT NOT NULL,
        content TEXT NOT NULL,
        summary TEXT DEFAULT '',
        author_id TEXT NOT NULL,
        status TEXT DEFAULT 'draft',
        view_count INTEGER DEFAULT 0,
        like_count INTEGER DEFAULT 0,
        comment_count INTEGER DEFAULT 0,
        collect_count INTEGER DEFAULT 0,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        published_at DATETIME,
        FOREIGN KEY (author_id) REFERENCES users(id) ON DELETE CASCADE,
        CHECK (status IN ('draft', 'published', 'archived'))
      );
      
      -- æ–‡ç« æ ‡ç­¾è¡¨
      CREATE TABLE IF NOT EXISTS article_tags (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        article_id TEXT NOT NULL,
        tag TEXT NOT NULL,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (article_id) REFERENCES articles(id) ON DELETE CASCADE,
        UNIQUE(article_id, tag)
      );
      
      -- è¯„è®ºè¡¨
      CREATE TABLE IF NOT EXISTS comments (
        id TEXT PRIMARY KEY,
        content TEXT NOT NULL,
        author_id TEXT NOT NULL,
        source_id TEXT NOT NULL,
        source_type TEXT NOT NULL,
        parent_id TEXT,
        root_id TEXT,
        reply_to_user_id TEXT,
        like_count INTEGER DEFAULT 0,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (author_id) REFERENCES users(id) ON DELETE CASCADE,
        CHECK (source_type IN ('article', 'comment', 'user'))
      );
      
      -- ç‚¹èµæ”¶è—è¡¨
      CREATE TABLE IF NOT EXISTS praises (
        id TEXT PRIMARY KEY,
        user_id TEXT NOT NULL,
        source_id TEXT NOT NULL,
        source_type TEXT NOT NULL,
        action_type TEXT NOT NULL,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
        UNIQUE(user_id, source_id, source_type, action_type),
        CHECK (source_type IN ('article', 'comment', 'user')),
        CHECK (action_type IN ('like', 'collect', 'follow'))
      );
      
      -- ç”¨æˆ·ç»Ÿè®¡è¡¨
      CREATE TABLE IF NOT EXISTS user_stats (
        user_id TEXT PRIMARY KEY,
        article_count INTEGER DEFAULT 0,
        published_count INTEGER DEFAULT 0,
        draft_count INTEGER DEFAULT 0,
        total_views INTEGER DEFAULT 0,
        total_likes INTEGER DEFAULT 0,
        total_comments INTEGER DEFAULT 0,
        follower_count INTEGER DEFAULT 0,
        following_count INTEGER DEFAULT 0,
        last_active DATETIME DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
      );
    `

    // ä½¿ç”¨äº‹åŠ¡åˆ›å»ºæ‰€æœ‰è¡¨
    const transaction = this.db.transaction(() => {
      this.db.exec(schema)
    })

    transaction()
    console.log(chalk.green('âœ“ æ•°æ®åº“è¡¨ç»“æ„åˆ›å»ºå®Œæˆ'))
  }

  private async importTable(
    filename: string,
    tablename: string,
  ): Promise<number> {
    const exportDir = join(process.cwd(), 'exports')
    const filePath = join(exportDir, filename)

    let data: any[]
    try {
      const fileContent = readFileSync(filePath, 'utf8')
      data = JSON.parse(fileContent)
    } catch (error) {
      console.warn(chalk.orange(`âš ï¸  æ–‡ä»¶ ${filename} ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡`))
      return 0
    }

    if (!data || data.length === 0) {
      console.warn(chalk.orange(`âš ï¸  ${tablename} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡`))
      return 0
    }

    // æ ¹æ®è¡¨åç”Ÿæˆæ’å…¥è¯­å¥
    const insertSQL = this.generateInsertSQL(tablename, data[0])
    const insertStmt = this.db.prepare(insertSQL)

    // åˆ†æ‰¹æ’å…¥æ•°æ®
    let totalInserted = 0
    const batches = this.createBatches(data, this.batchSize)

    for (let i = 0; i < batches.length; i++) {
      const batch = batches[i]

      // ä½¿ç”¨äº‹åŠ¡æ‰¹é‡æ’å…¥
      const transaction = this.db.transaction(() => {
        for (const record of batch) {
          try {
            const values = this.extractValues(record, tablename)
            insertStmt.run(...values)
            totalInserted++
          } catch (error) {
            console.warn(chalk.orange(`âš ï¸  æ’å…¥è®°å½•å¤±è´¥: ${error.message}`))
            console.warn(
              chalk.gray(
                `   æ•°æ®: ${JSON.stringify(record).substring(0, 100)}...`,
              ),
            )
          }
        }
      })

      transaction()

      // æ˜¾ç¤ºè¿›åº¦
      const progress = (((i + 1) / batches.length) * 100).toFixed(1)
      process.stdout.write(
        `\\r   è¿›åº¦: ${progress}% (${totalInserted}/${data.length})`,
      )
    }

    console.log('') // æ¢è¡Œ
    return totalInserted
  }

  private generateInsertSQL(tablename: string, sampleRecord: any): string {
    const columns = Object.keys(sampleRecord).filter(
      key => sampleRecord[key] !== undefined,
    )
    const placeholders = columns.map(() => '?').join(', ')

    return `INSERT OR IGNORE INTO ${tablename} (${columns.join(', ')}) VALUES (${placeholders})`
  }

  private extractValues(record: any, tablename: string): any[] {
    const values = []

    for (const [key, value] of Object.entries(record)) {
      if (value === undefined) continue

      // å¤„ç†ç‰¹æ®Šæ•°æ®ç±»å‹
      if (value === null) {
        values.push(null)
      } else if (typeof value === 'boolean') {
        values.push(value ? 1 : 0)
      } else if (Array.isArray(value)) {
        values.push(JSON.stringify(value))
      } else if (typeof value === 'object') {
        values.push(JSON.stringify(value))
      } else {
        values.push(value)
      }
    }

    return values
  }

  private createBatches<T>(items: T[], batchSize: number): T[][] {
    const batches: T[][] = []
    for (let i = 0; i < items.length; i += batchSize) {
      batches.push(items.slice(i, i + batchSize))
    }
    return batches
  }

  private async createIndexes(): Promise<void> {
    console.log(chalk.yellow('ğŸ” åˆ›å»ºæ•°æ®åº“ç´¢å¼•...'))

    const indexes = `
      -- ç”¨æˆ·è¡¨ç´¢å¼•
      CREATE INDEX IF NOT EXISTS idx_users_phone ON users(phone);
      CREATE INDEX IF NOT EXISTS idx_users_username ON users(username);
      
      -- æ–‡ç« è¡¨ç´¢å¼•
      CREATE INDEX IF NOT EXISTS idx_articles_author_id ON articles(author_id);
      CREATE INDEX IF NOT EXISTS idx_articles_status ON articles(status);
      CREATE INDEX IF NOT EXISTS idx_articles_published_at ON articles(published_at DESC);
      CREATE INDEX IF NOT EXISTS idx_articles_created_at ON articles(created_at DESC);
      
      -- æ ‡ç­¾è¡¨ç´¢å¼•
      CREATE INDEX IF NOT EXISTS idx_article_tags_article_id ON article_tags(article_id);
      CREATE INDEX IF NOT EXISTS idx_article_tags_tag ON article_tags(tag);
      
      -- è¯„è®ºè¡¨ç´¢å¼•
      CREATE INDEX IF NOT EXISTS idx_comments_author_id ON comments(author_id);
      CREATE INDEX IF NOT EXISTS idx_comments_source_id ON comments(source_id);
      CREATE INDEX IF NOT EXISTS idx_comments_parent_id ON comments(parent_id);
      CREATE INDEX IF NOT EXISTS idx_comments_created_at ON comments(created_at DESC);
      
      -- ç‚¹èµè¡¨ç´¢å¼•
      CREATE INDEX IF NOT EXISTS idx_praises_user_id ON praises(user_id);
      CREATE INDEX IF NOT EXISTS idx_praises_source ON praises(source_id, source_type);
      CREATE INDEX IF NOT EXISTS idx_praises_composite ON praises(source_id, source_type, action_type);
    `

    this.db.exec(indexes)
    console.log(chalk.green('âœ“ æ•°æ®åº“ç´¢å¼•åˆ›å»ºå®Œæˆ'))
  }

  private async validateImport(): Promise<void> {
    console.log(chalk.yellow('ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...'))

    // ç»Ÿè®¡å„è¡¨è®°å½•æ•°
    const tables = ['users', 'articles', 'article_tags', 'comments']
    const counts = {}

    for (const table of tables) {
      const result = this.db
        .prepare(`SELECT COUNT(*) as count FROM ${table}`)
        .get()
      counts[table] = result.count
    }

    // éªŒè¯å¤–é”®çº¦æŸ
    const validationQueries = [
      {
        name: 'å­¤ç«‹æ–‡ç« æ£€æŸ¥',
        query: `SELECT COUNT(*) as count FROM articles a 
                LEFT JOIN users u ON a.author_id = u.id 
                WHERE u.id IS NULL`,
      },
      {
        name: 'å­¤ç«‹è¯„è®ºæ£€æŸ¥',
        query: `SELECT COUNT(*) as count FROM comments c 
                LEFT JOIN users u ON c.author_id = u.id 
                WHERE u.id IS NULL`,
      },
      {
        name: 'å­¤ç«‹æ ‡ç­¾æ£€æŸ¥',
        query: `SELECT COUNT(*) as count FROM article_tags t 
                LEFT JOIN articles a ON t.article_id = a.id 
                WHERE a.id IS NULL`,
      },
    ]

    for (const validation of validationQueries) {
      const result = this.db.prepare(validation.query).get()
      if (result.count > 0) {
        console.warn(
          chalk.orange(`âš ï¸  ${validation.name}: ${result.count} æ¡å¼‚å¸¸è®°å½•`),
        )
      } else {
        console.log(chalk.green(`âœ“ ${validation.name}: é€šè¿‡`))
      }
    }

    console.log(chalk.blue('\\nğŸ“Š æ•°æ®ç»Ÿè®¡:'))
    Object.entries(counts).forEach(([table, count]) => {
      console.log(chalk.white(`  ${table}: ${count} æ¡`))
    })
  }
}

// ä¸»æ‰§è¡Œå‡½æ•°
async function main() {
  try {
    const dbPath = process.env.D1_LOCAL_PATH || './local.db'

    console.log(chalk.blue(`ğŸ“‚ ä½¿ç”¨æ•°æ®åº“: ${dbPath}`))

    const importer = new D1Importer(dbPath)
    const result = await importer.importAll()

    if (result.success) {
      console.log(chalk.green('\\nğŸŠ æ•°æ®å¯¼å…¥ä»»åŠ¡å®Œæˆï¼'))
      process.exit(0)
    } else {
      console.log(chalk.red('\\nğŸ’¥ æ•°æ®å¯¼å…¥å¤±è´¥'))
      process.exit(1)
    }
  } catch (error) {
    console.error(chalk.red('âŒ å¯¼å…¥ä»»åŠ¡å¼‚å¸¸:'), error)
    process.exit(1)
  }
}

if (require.main === module) {
  main()
}

export { D1Importer }
```

### æ­¥éª¤2ï¼šåˆ›å»ºç”Ÿäº§ç¯å¢ƒå¯¼å…¥è„šæœ¬

```typescript
// src/import-to-d1.ts (ç”¨äºç”Ÿäº§ç¯å¢ƒ D1)
import { readFileSync } from 'fs'
import { join } from 'path'
import chalk from 'chalk'
import dotenv from 'dotenv'

dotenv.config()

interface CloudflareD1Client {
  accountId: string
  databaseId: string
  apiToken: string
}

class CloudflareD1Importer {
  private client: CloudflareD1Client

  constructor() {
    this.client = {
      accountId: process.env.CLOUDFLARE_ACCOUNT_ID!,
      databaseId: process.env.D1_DATABASE_ID!,
      apiToken: process.env.CLOUDFLARE_API_TOKEN!,
    }

    if (
      !this.client.accountId ||
      !this.client.databaseId ||
      !this.client.apiToken
    ) {
      throw new Error('ç¼ºå°‘å¿…è¦çš„ Cloudflare é…ç½®')
    }
  }

  async importToD1(): Promise<void> {
    console.log(chalk.blue('â˜ï¸  å¼€å§‹å¯¼å…¥åˆ° Cloudflare D1...'))

    try {
      // 1. åˆ›å»ºè¡¨ç»“æ„
      await this.createTablesInD1()

      // 2. å¯¼å…¥æ•°æ®
      const importOrder = [
        { file: 'users.json', table: 'users' },
        { file: 'articles.json', table: 'articles' },
        { file: 'article_tags.json', table: 'article_tags' },
        { file: 'comments.json', table: 'comments' },
      ]

      for (const { file, table } of importOrder) {
        await this.importTableToD1(file, table)
      }

      // 3. åˆ›å»ºç´¢å¼•
      await this.createIndexesInD1()

      console.log(chalk.green('\\nğŸ‰ D1 æ•°æ®å¯¼å…¥å®Œæˆï¼'))
    } catch (error) {
      console.error(chalk.red('âŒ D1 å¯¼å…¥å¤±è´¥:'), error)
      throw error
    }
  }

  private async executeD1Query(sql: string, params: any[] = []): Promise<any> {
    const url = `https://api.cloudflare.com/client/v4/accounts/${this.client.accountId}/d1/database/${this.client.databaseId}/query`

    const response = await fetch(url, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${this.client.apiToken}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        sql,
        params,
      }),
    })

    if (!response.ok) {
      const error = await response.text()
      throw new Error(`D1 æŸ¥è¯¢å¤±è´¥: ${response.status} ${error}`)
    }

    return await response.json()
  }

  private async createTablesInD1(): Promise<void> {
    console.log(chalk.yellow('ğŸ—ï¸  åœ¨ D1 ä¸­åˆ›å»ºè¡¨ç»“æ„...'))

    const schema = `
      CREATE TABLE IF NOT EXISTS users (
        id TEXT PRIMARY KEY,
        phone TEXT UNIQUE NOT NULL,
        username TEXT NOT NULL,
        password TEXT NOT NULL,
        avatar TEXT DEFAULT '',
        introduc TEXT DEFAULT '',
        position TEXT DEFAULT '',
        company TEXT DEFAULT '',
        location TEXT DEFAULT '',
        website TEXT DEFAULT '',
        github TEXT DEFAULT '',
        jue_power INTEGER DEFAULT 0,
        good_num INTEGER DEFAULT 0,
        read_num INTEGER DEFAULT 0,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
      )
    `

    await this.executeD1Query(schema)
    console.log(chalk.green('âœ“ D1 è¡¨ç»“æ„åˆ›å»ºå®Œæˆ'))
  }

  private async importTableToD1(
    filename: string,
    tablename: string,
  ): Promise<void> {
    console.log(chalk.yellow(`ğŸ“¥ å¯¼å…¥ ${tablename} åˆ° D1...`))

    const exportDir = join(process.cwd(), 'exports')
    const filePath = join(exportDir, filename)

    let data: any[]
    try {
      const fileContent = readFileSync(filePath, 'utf8')
      data = JSON.parse(fileContent)
    } catch (error) {
      console.warn(chalk.orange(`âš ï¸  æ–‡ä»¶ ${filename} ä¸å­˜åœ¨ï¼Œè·³è¿‡`))
      return
    }

    if (!data || data.length === 0) {
      console.warn(chalk.orange(`âš ï¸  ${tablename} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡`))
      return
    }

    // åˆ†æ‰¹æ’å…¥ï¼ˆD1 æœ‰æŸ¥è¯¢å¤§å°é™åˆ¶ï¼‰
    const batchSize = 100
    const batches = this.createBatches(data, batchSize)

    for (let i = 0; i < batches.length; i++) {
      const batch = batches[i]

      // æ„å»ºæ‰¹é‡æ’å…¥è¯­å¥
      const insertSQL = this.buildBatchInsertSQL(tablename, batch)

      try {
        await this.executeD1Query(insertSQL)

        const progress = (((i + 1) / batches.length) * 100).toFixed(1)
        process.stdout.write(`\\r   è¿›åº¦: ${progress}%`)
      } catch (error) {
        console.error(chalk.red(`\\n   æ‰¹æ¬¡ ${i + 1} å¯¼å…¥å¤±è´¥:`, error.message))
      }
    }

    console.log(
      chalk.green(`\\nâœ“ ${tablename} å¯¼å…¥å®Œæˆ: ${data.length} æ¡è®°å½•`),
    )
  }

  private buildBatchInsertSQL(tablename: string, records: any[]): string {
    if (records.length === 0) return ''

    const columns = Object.keys(records[0])
    const values = records.map(record => {
      const valueList = columns.map(col => {
        const value = record[col]
        if (value === null || value === undefined) return 'NULL'
        if (typeof value === 'string') return `'${value.replace(/'/g, "''")}'`
        if (typeof value === 'boolean') return value ? '1' : '0'
        return value.toString()
      })
      return `(${valueList.join(', ')})`
    })

    return `INSERT OR IGNORE INTO ${tablename} (${columns.join(', ')}) VALUES ${values.join(', ')}`
  }

  private async createIndexesInD1(): Promise<void> {
    console.log(chalk.yellow('ğŸ” åœ¨ D1 ä¸­åˆ›å»ºç´¢å¼•...'))

    const indexes = [
      'CREATE INDEX IF NOT EXISTS idx_users_phone ON users(phone)',
      'CREATE INDEX IF NOT EXISTS idx_articles_author_id ON articles(author_id)',
      'CREATE INDEX IF NOT EXISTS idx_comments_source_id ON comments(source_id)',
    ]

    for (const indexSQL of indexes) {
      try {
        await this.executeD1Query(indexSQL)
      } catch (error) {
        console.warn(chalk.orange(`âš ï¸  ç´¢å¼•åˆ›å»ºå¤±è´¥: ${error.message}`))
      }
    }

    console.log(chalk.green('âœ“ D1 ç´¢å¼•åˆ›å»ºå®Œæˆ'))
  }

  private createBatches<T>(items: T[], batchSize: number): T[][] {
    const batches: T[][] = []
    for (let i = 0; i < items.length; i += batchSize) {
      batches.push(items.slice(i, i + batchSize))
    }
    return batches
  }
}

// ä¸»æ‰§è¡Œå‡½æ•°
async function main() {
  try {
    const importer = new CloudflareD1Importer()
    await importer.importToD1()

    console.log(chalk.green('\\nğŸŠ Cloudflare D1 å¯¼å…¥ä»»åŠ¡å®Œæˆï¼'))
  } catch (error) {
    console.error(chalk.red('âŒ D1 å¯¼å…¥ä»»åŠ¡å¤±è´¥:'), error)
    process.exit(1)
  }
}

if (require.main === module) {
  main()
}

export { CloudflareD1Importer }
```

### æ­¥éª¤3ï¼šæ•°æ®åŒæ­¥éªŒè¯å·¥å…·

```typescript
// src/sync-verify.ts
import Database from 'better-sqlite3'
import { MongoClient } from 'mongodb'
import { readFileSync } from 'fs'
import { join } from 'path'
import chalk from 'chalk'
import dotenv from 'dotenv'

dotenv.config()

interface SyncResult {
  isConsistent: boolean
  differences: {
    table: string
    mongoCount: number
    d1Count: number
    difference: number
  }[]
  errors: string[]
}

class SyncValidator {
  private mongoClient: MongoClient
  private d1Database: Database.Database
  private idMapping: Map<string, string>

  constructor(
    private mongoUrl: string,
    private mongoDbName: string,
    private d1Path: string,
  ) {
    this.mongoClient = new MongoClient(mongoUrl)
    this.d1Database = new Database(d1Path)
    this.idMapping = new Map()

    // åŠ è½½ ID æ˜ å°„
    this.loadIdMapping()
  }

  private loadIdMapping(): void {
    try {
      const mappingPath = join(process.cwd(), 'exports', 'id_mapping.json')
      const mapping = JSON.parse(readFileSync(mappingPath, 'utf8'))
      this.idMapping = new Map(Object.entries(mapping))
    } catch (error) {
      console.warn(chalk.orange('âš ï¸  æ— æ³•åŠ è½½ ID æ˜ å°„æ–‡ä»¶'))
    }
  }

  async validateSync(): Promise<SyncResult> {
    console.log(chalk.blue('ğŸ” å¼€å§‹éªŒè¯æ•°æ®åŒæ­¥ä¸€è‡´æ€§...'))

    const result: SyncResult = {
      isConsistent: true,
      differences: [],
      errors: [],
    }

    try {
      await this.mongoClient.connect()
      const mongoDb = this.mongoClient.db(this.mongoDbName)

      // éªŒè¯å„è¡¨æ•°æ®ä¸€è‡´æ€§
      const collections = [
        { mongo: 'users', d1: 'users' },
        { mongo: 'articles', d1: 'articles' },
        { mongo: 'comments', d1: 'comments' },
      ]

      for (const { mongo, d1 } of collections) {
        const mongoCount = await mongoDb.collection(mongo).countDocuments()
        const d1Count = this.d1Database
          .prepare(`SELECT COUNT(*) as count FROM ${d1}`)
          .get().count

        const difference = Math.abs(mongoCount - d1Count)

        result.differences.push({
          table: d1,
          mongoCount,
          d1Count,
          difference,
        })

        if (difference > 0) {
          result.isConsistent = false
        }

        console.log(
          chalk.white(
            `${d1}: MongoDB(${mongoCount}) vs D1(${d1Count}) å·®å¼‚: ${difference}`,
          ),
        )
      }

      // éªŒè¯å…³é”®æ•°æ®çš„å†…å®¹ä¸€è‡´æ€§
      await this.validateSampleData(mongoDb, result)

      if (result.isConsistent) {
        console.log(chalk.green('âœ“ æ•°æ®åŒæ­¥ä¸€è‡´æ€§éªŒè¯é€šè¿‡'))
      } else {
        console.log(chalk.red('âŒ å‘ç°æ•°æ®ä¸ä¸€è‡´'))
      }

      return result
    } catch (error) {
      result.errors.push(error.message)
      console.error(chalk.red('âŒ åŒæ­¥éªŒè¯å¤±è´¥:'), error)
      return result
    } finally {
      await this.mongoClient.close()
      this.d1Database.close()
    }
  }

  private async validateSampleData(
    mongoDb: any,
    result: SyncResult,
  ): Promise<void> {
    console.log(chalk.yellow('ğŸ” éªŒè¯æ ·æœ¬æ•°æ®å†…å®¹ä¸€è‡´æ€§...'))

    try {
      // éªŒè¯ç”¨æˆ·æ•°æ®æ ·æœ¬
      const mongoUsers = await mongoDb
        .collection('users')
        .find({})
        .limit(10)
        .toArray()

      for (const mongoUser of mongoUsers) {
        const d1UserId = this.idMapping.get(mongoUser._id.toString())
        if (!d1UserId) continue

        const d1User = this.d1Database
          .prepare('SELECT * FROM users WHERE id = ?')
          .get(d1UserId)

        if (!d1User) {
          result.errors.push(`ç”¨æˆ· ${mongoUser.username} åœ¨ D1 ä¸­ä¸å­˜åœ¨`)
          continue
        }

        // éªŒè¯å…³é”®å­—æ®µ
        if (mongoUser.username !== d1User.username) {
          result.errors.push(`ç”¨æˆ· ${mongoUser.username} çš„ç”¨æˆ·åä¸åŒ¹é…`)
        }

        if (mongoUser.phone !== d1User.phone) {
          result.errors.push(`ç”¨æˆ· ${mongoUser.username} çš„æ‰‹æœºå·ä¸åŒ¹é…`)
        }
      }

      console.log(
        chalk.green(`âœ“ æ ·æœ¬æ•°æ®éªŒè¯å®Œæˆï¼Œå‘ç° ${result.errors.length} ä¸ªé—®é¢˜`),
      )
    } catch (error) {
      result.errors.push(`æ ·æœ¬æ•°æ®éªŒè¯å¤±è´¥: ${error.message}`)
    }
  }
}

// ä¸»æ‰§è¡Œå‡½æ•°
async function main() {
  try {
    const mongoUrl = process.env.MONGO_URL || 'mongodb://localhost:27017'
    const mongoDbName = process.env.MONGO_DB_NAME || 'vue_blog'
    const d1Path = process.env.D1_LOCAL_PATH || './local.db'

    const validator = new SyncValidator(mongoUrl, mongoDbName, d1Path)
    const result = await validator.validateSync()

    console.log(chalk.blue('\\nğŸ“Š éªŒè¯ç»“æœæ‘˜è¦:'))
    result.differences.forEach(diff => {
      const status = diff.difference === 0 ? 'âœ“' : 'âŒ'
      console.log(
        chalk.white(`${status} ${diff.table}: ${diff.difference} æ¡å·®å¼‚`),
      )
    })

    if (result.errors.length > 0) {
      console.log(chalk.red('\\né”™è¯¯è¯¦æƒ…:'))
      result.errors.forEach(error => console.log(chalk.red(`  - ${error}`)))
    }

    process.exit(result.isConsistent ? 0 : 1)
  } catch (error) {
    console.error(chalk.red('âŒ åŒæ­¥éªŒè¯ä»»åŠ¡å¤±è´¥:'), error)
    process.exit(1)
  }
}

if (require.main === module) {
  main()
}

export { SyncValidator }
```

### æ­¥éª¤4ï¼šæ›´æ–° package.json è„šæœ¬

```json
{
  "scripts": {
    "export": "ts-node src/export.ts",
    "import": "ts-node src/import.ts",
    "import:d1": "ts-node src/import-to-d1.ts",
    "verify": "ts-node src/verify.ts",
    "sync:verify": "ts-node src/sync-verify.ts",
    "migrate": "npm run export && npm run import && npm run verify",
    "migrate:full": "npm run export && npm run import && npm run import:d1 && npm run sync:verify"
  }
}
```

## ğŸ” æ·±å…¥æ€è€ƒ

### D1 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### æ‰¹é‡æ’å…¥ä¼˜åŒ–

```typescript
// ä¼˜åŒ–çš„æ‰¹é‡æ’å…¥ç­–ç•¥
class OptimizedBatchImporter {
  private async importWithTransaction(
    data: any[],
    table: string,
    batchSize: number = 500,
  ): Promise<void> {
    const batches = this.createBatches(data, batchSize)

    for (const batch of batches) {
      // ä½¿ç”¨äº‹åŠ¡ç¡®ä¿æ‰¹æ¬¡å®Œæ•´æ€§
      const transaction = this.db.transaction(() => {
        const stmt = this.db.prepare(this.getInsertSQL(table))

        for (const record of batch) {
          stmt.run(...this.extractValues(record))
        }
      })

      // æ‰§è¡Œäº‹åŠ¡
      transaction()
    }
  }
}
```

#### ç´¢å¼•åˆ›å»ºæ—¶æœº

```sql
-- ç­–ç•¥ï¼šå…ˆæ’å…¥æ•°æ®ï¼Œååˆ›å»ºç´¢å¼•
-- 1. æ•°æ®å¯¼å…¥é˜¶æ®µï¼ˆæ— ç´¢å¼•ï¼‰
INSERT INTO users VALUES (...);  -- å¿«é€Ÿæ’å…¥

-- 2. ç´¢å¼•åˆ›å»ºé˜¶æ®µï¼ˆæ•°æ®å¯¼å…¥å®Œæˆåï¼‰
CREATE INDEX idx_users_phone ON users(phone);  -- æ‰¹é‡åˆ›å»ºç´¢å¼•
```

## â“ é‡åˆ°çš„é—®é¢˜

### é—®é¢˜ 1ï¼šD1 æŸ¥è¯¢å¤§å°é™åˆ¶

**é—®é¢˜æè¿°**ï¼šCloudflare D1 å•æ¬¡æŸ¥è¯¢æœ€å¤§ 25MBï¼Œå¤§æ‰¹é‡æ’å…¥å¤±è´¥  
**è§£å†³æ–¹æ¡ˆ**ï¼š

```typescript
// åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
const estimateQuerySize = (records: any[]): number => {
  const sampleSize = JSON.stringify(records[0]).length
  return records.length * sampleSize * 1.5 // é¢„ç•™ä½™é‡
}

const getOptimalBatchSize = (records: any[]): number => {
  const maxSize = 20 * 1024 * 1024 // 20MB å®‰å…¨é˜ˆå€¼
  const estimatedSize = estimateQuerySize([records[0]])
  return Math.floor(maxSize / estimatedSize)
}
```

### é—®é¢˜ 2ï¼šå¹¶å‘å†™å…¥å†²çª

**é—®é¢˜æè¿°**ï¼šå¤šä¸ªå¯¼å…¥è¿›ç¨‹åŒæ—¶å†™å…¥å¯¼è‡´é”å†²çª  
**è§£å†³æ–¹æ¡ˆ**ï¼š

```typescript
// ä¸²è¡ŒåŒ–å¯¼å…¥æµç¨‹
const importSequentially = async (tables: string[]) => {
  for (const table of tables) {
    console.log(`å¯¼å…¥ ${table}...`)
    await importTable(table)
    console.log(`${table} å¯¼å…¥å®Œæˆ`)

    // æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿ç»­å†™å…¥å‹åŠ›
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
}
```

### é—®é¢˜ 3ï¼šå¤–é”®çº¦æŸå¯¼å…¥é¡ºåº

**é—®é¢˜æè¿°**ï¼šè¿åå¤–é”®çº¦æŸå¯¼è‡´å¯¼å…¥å¤±è´¥  
**è§£å†³æ–¹æ¡ˆ**ï¼š

```typescript
// ä¸¥æ ¼æŒ‰ç…§ä¾èµ–å…³ç³»æ’åº
const DEPENDENCY_ORDER = {
  users: [], // æ— ä¾èµ–
  articles: ['users'], // ä¾èµ–ç”¨æˆ·
  article_tags: ['articles'], // ä¾èµ–æ–‡ç« 
  comments: ['users', 'articles'], // ä¾èµ–ç”¨æˆ·å’Œæ–‡ç« 
  praises: ['users', 'articles', 'comments'], // ä¾èµ–æ‰€æœ‰
}

const sortByDependency = (tables: string[]): string[] => {
  return tables.sort((a, b) => {
    const aDeps = DEPENDENCY_ORDER[a]?.length || 0
    const bDeps = DEPENDENCY_ORDER[b]?.length || 0
    return aDeps - bDeps
  })
}
```

## ğŸ’¡ ä¸ªäººå¿ƒå¾—

### ä»Šå¤©æœ€å¤§çš„æ”¶è·

æˆåŠŸå®ç°äº†ä» JSON æ•°æ®åˆ° D1 æ•°æ®åº“çš„å®Œæ•´å¯¼å…¥æµç¨‹ï¼Œç†è§£äº†åˆ†å¸ƒå¼æ•°æ®åº“çš„å¯¼å…¥ç­–ç•¥å’Œæ€§èƒ½ä¼˜åŒ–æ–¹æ³•ã€‚

### æ•°æ®å¯¼å…¥çš„å…³é”®ç»éªŒ

1. **æ‰¹é‡æ“ä½œçš„é‡è¦æ€§**ï¼šåˆç†çš„æ‰¹æ¬¡å¤§å°èƒ½æ˜¾è‘—æå‡å¯¼å…¥æ€§èƒ½
2. **äº‹åŠ¡çš„å¿…è¦æ€§**ï¼šç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼Œé¿å…éƒ¨åˆ†å¤±è´¥çŠ¶æ€
3. **ä¾èµ–å…³ç³»ç®¡ç†**ï¼šä¸¥æ ¼æŒ‰ç…§å¤–é”®ä¾èµ–é¡ºåºå¯¼å…¥æ•°æ®
4. **é”™è¯¯å¤„ç†ç­–ç•¥**ï¼šå®¹é”™è®¾è®¡å’Œè¯¦ç»†çš„æ—¥å¿—è®°å½•

## ğŸ“‹ è¡ŒåŠ¨æ¸…å•

### ä»Šæ—¥å®Œæˆ

- [x] å®ç°æœ¬åœ° SQLite æ•°æ®å¯¼å…¥åŠŸèƒ½
- [x] åˆ›å»º Cloudflare D1 è¿œç¨‹å¯¼å…¥å·¥å…·
- [x] å»ºç«‹æ•°æ®åŒæ­¥éªŒè¯æœºåˆ¶
- [x] ä¼˜åŒ–æ‰¹é‡å¯¼å…¥æ€§èƒ½å’Œé”™è¯¯å¤„ç†

### æ˜æ—¥é¢„ä¹ 

- [ ] äº†è§£å‰ç«¯æ„å»ºä¼˜åŒ–æŠ€æœ¯
- [ ] æ€è€ƒç”Ÿäº§ç¯å¢ƒé…ç½®ç®¡ç†
- [ ] å‡†å¤‡æ€§èƒ½ç›‘æ§å’Œé”™è¯¯è¿½è¸ª

## ğŸ”— æœ‰ç”¨é“¾æ¥

- [Cloudflare D1 æ–‡æ¡£](https://developers.cloudflare.com/d1/)
- [SQLite æ€§èƒ½ä¼˜åŒ–](https://www.sqlite.org/optoverview.html)
- [æ‰¹é‡æ•°æ®å¯¼å…¥æœ€ä½³å®è·µ](https://sqlite.org/lang_insert.html)

---

**ğŸ“ æ˜æ—¥é‡ç‚¹**ï¼šä¼˜åŒ–å‰ç«¯æ„å»ºé…ç½®ï¼Œå®ç°ç”Ÿäº§ç¯å¢ƒçš„æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯ç›‘æ§ã€‚
