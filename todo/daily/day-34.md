# Day 34: æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

> ğŸ“… **æ—¥æœŸ**ï¼š**\_**  
> â° **è®¡åˆ’æ—¶é•¿**ï¼š1å°æ—¶  
> â±ï¸ **å®é™…æ—¶é•¿**ï¼š**\_**  
> ğŸ“Š **å®Œæˆåº¦**ï¼š\_\_\_\_%

## ğŸ¯ ä»Šæ—¥ä»»åŠ¡

- [ ] é…ç½® Cloudflare Analytics
- [ ] ç›‘æ§ API å“åº”æ—¶é—´å’Œé”™è¯¯ç‡
- [ ] ä¼˜åŒ–æ…¢æŸ¥è¯¢å’Œæ€§èƒ½ç“¶é¢ˆ
- [ ] è®¾ç½®ç”¨æˆ·ä½“éªŒç›‘æ§

## ğŸ“š å­¦ä¹ ç¬”è®°

### å…¨æ ˆæ€§èƒ½ç›‘æ§ä½“ç³»

#### æ€§èƒ½ç›‘æ§é‡‘å­—å¡”

```
                    ç”¨æˆ·ä½“éªŒç›‘æ§
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Core Web Vitals â”‚
                 â”‚  Real User       â”‚
                 â”‚  Monitoring      â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   åº”ç”¨æ€§èƒ½ç›‘æ§       â”‚
               â”‚   APIå“åº”æ—¶é—´       â”‚
               â”‚   é”™è¯¯ç‡ç»Ÿè®¡         â”‚
               â”‚   ä¸šåŠ¡æŒ‡æ ‡è¿½è¸ª       â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      åŸºç¡€è®¾æ–½ç›‘æ§        â”‚
            â”‚   Workers CPU/å†…å­˜      â”‚
            â”‚   D1 æ•°æ®åº“æ€§èƒ½         â”‚
            â”‚   ç½‘ç»œå»¶è¿Ÿç»Ÿè®¡          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç›‘æ§å±‚æ¬¡åˆ’åˆ†**ï¼š

1. **ç”¨æˆ·ä½“éªŒç›‘æ§**ï¼šå…³æ³¨çœŸå®ç”¨æˆ·æ„Ÿå—çš„æ€§èƒ½æŒ‡æ ‡
2. **åº”ç”¨æ€§èƒ½ç›‘æ§**ï¼šè¿½è¸ª API å’Œä¸šåŠ¡é€»è¾‘æ€§èƒ½
3. **åŸºç¡€è®¾æ–½ç›‘æ§**ï¼šç›‘æ§åº•å±‚èµ„æºä½¿ç”¨æƒ…å†µ

#### Cloudflare Analytics æ·±åº¦é›†æˆ

```typescript
// src/utils/analytics-engine.ts
export interface PerformanceMetrics {
  // è¯·æ±‚åŸºç¡€ä¿¡æ¯
  timestamp: number
  requestId: string
  endpoint: string
  method: string
  status: number

  // æ€§èƒ½æŒ‡æ ‡
  duration: number
  dbQueryTime: number
  computeTime: number
  networkTime: number

  // ç”¨æˆ·ç›¸å…³
  userId?: string
  userAgent: string
  country: string
  colo: string // Cloudflare æ•°æ®ä¸­å¿ƒ

  // ä¸šåŠ¡æŒ‡æ ‡
  feature?: string
  businessMetric?: number
  errorCode?: string
  stackTrace?: string
}

export class CloudflareAnalyticsEngine {
  private dataset: string
  private batchSize = 100
  private batchTimeout = 5000 // 5ç§’
  private metricsBuffer: PerformanceMetrics[] = []
  private flushTimer?: NodeJS.Timeout

  constructor(dataset: string) {
    this.dataset = dataset
  }

  async track(metrics: PerformanceMetrics, env: any) {
    // æ·»åŠ åˆ°æ‰¹å¤„ç†ç¼“å†²åŒº
    this.metricsBuffer.push({
      ...metrics,
      timestamp: Date.now(),
    })

    // è¾¾åˆ°æ‰¹æ¬¡å¤§å°æ—¶ç«‹å³å‘é€
    if (this.metricsBuffer.length >= this.batchSize) {
      await this.flush(env)
    } else if (!this.flushTimer) {
      // è®¾ç½®å®šæ—¶å™¨ç¡®ä¿æ•°æ®ä¸ä¼šåœ¨ç¼“å†²åŒºä¸­åœç•™å¤ªä¹…
      this.flushTimer = setTimeout(() => this.flush(env), this.batchTimeout)
    }
  }

  private async flush(env: any) {
    if (this.metricsBuffer.length === 0) return

    const batch = [...this.metricsBuffer]
    this.metricsBuffer = []

    if (this.flushTimer) {
      clearTimeout(this.flushTimer)
      this.flushTimer = undefined
    }

    try {
      if (env.ANALYTICS_ENGINE) {
        await Promise.all(
          batch.map(metrics =>
            env.ANALYTICS_ENGINE.writeDataPoint({
              blobs: [
                metrics.requestId,
                metrics.endpoint,
                metrics.method,
                metrics.userAgent,
                metrics.country,
                metrics.colo,
                metrics.feature || 'unknown',
                metrics.errorCode || '',
              ],
              doubles: [
                metrics.timestamp,
                metrics.status,
                metrics.duration,
                metrics.dbQueryTime,
                metrics.computeTime,
                metrics.networkTime,
                metrics.businessMetric || 0,
              ],
              indexes: [
                metrics.endpoint,
                metrics.status.toString(),
                metrics.country,
                metrics.feature || 'unknown',
              ],
            }),
          ),
        )
      }

      // åŒæ—¶å‘é€åˆ°å¤šä¸ªç›‘æ§å¹³å°
      await this.sendToExternalMonitoring(batch)
    } catch (error) {
      console.error('Failed to flush analytics data:', error)
      // å¤±è´¥çš„æ•°æ®é‡æ–°åŠ å…¥ç¼“å†²åŒºï¼ˆé¿å…æ•°æ®ä¸¢å¤±ï¼‰
      this.metricsBuffer.unshift(...batch)
    }
  }

  private async sendToExternalMonitoring(metrics: PerformanceMetrics[]) {
    // å‘é€åˆ°å…¶ä»–ç›‘æ§å¹³å°ï¼ˆå¦‚ Datadogã€New Relic ç­‰ï¼‰
    const summaryData = this.aggregateMetrics(metrics)

    await Promise.allSettled([
      this.sendToDatadog(summaryData),
      this.sendToSlack(this.detectAnomalies(summaryData)),
      this.updateHealthStatus(summaryData),
    ])
  }

  private aggregateMetrics(metrics: PerformanceMetrics[]) {
    const grouped = metrics.reduce(
      (acc, metric) => {
        const key = `${metric.endpoint}:${metric.method}`
        if (!acc[key]) {
          acc[key] = []
        }
        acc[key].push(metric)
        return acc
      },
      {} as Record<string, PerformanceMetrics[]>,
    )

    return Object.entries(grouped).map(([endpoint, endpointMetrics]) => ({
      endpoint,
      count: endpointMetrics.length,
      avgDuration:
        endpointMetrics.reduce((sum, m) => sum + m.duration, 0) /
        endpointMetrics.length,
      avgDbTime:
        endpointMetrics.reduce((sum, m) => sum + m.dbQueryTime, 0) /
        endpointMetrics.length,
      errorRate:
        endpointMetrics.filter(m => m.status >= 400).length /
        endpointMetrics.length,
      p95Duration: this.calculatePercentile(
        endpointMetrics.map(m => m.duration),
        95,
      ),
      p99Duration: this.calculatePercentile(
        endpointMetrics.map(m => m.duration),
        99,
      ),
      topCountries: this.getTopCountries(endpointMetrics),
      timeRange: {
        start: Math.min(...endpointMetrics.map(m => m.timestamp)),
        end: Math.max(...endpointMetrics.map(m => m.timestamp)),
      },
    }))
  }

  private calculatePercentile(values: number[], percentile: number): number {
    const sorted = values.sort((a, b) => a - b)
    const index = Math.ceil((percentile / 100) * sorted.length) - 1
    return sorted[Math.max(0, index)]
  }

  private getTopCountries(
    metrics: PerformanceMetrics[],
  ): Record<string, number> {
    return metrics.reduce(
      (acc, m) => {
        acc[m.country] = (acc[m.country] || 0) + 1
        return acc
      },
      {} as Record<string, number>,
    )
  }

  private detectAnomalies(summaryData: any[]): any[] {
    return summaryData.filter(data => {
      return (
        data.avgDuration > 2000 || // å¹³å‡å“åº”æ—¶é—´è¶…è¿‡2ç§’
        data.errorRate > 0.05 || // é”™è¯¯ç‡è¶…è¿‡5%
        data.p99Duration > 10000 // 99åˆ†ä½å“åº”æ—¶é—´è¶…è¿‡10ç§’
      )
    })
  }

  private async sendToDatadog(summaryData: any[]) {
    // å‘é€åˆ° Datadog çš„å®ç°
    const datadogMetrics = summaryData.map(data => ({
      metric: 'vue_blog.api.performance',
      points: [[Date.now() / 1000, data.avgDuration]],
      tags: [`endpoint:${data.endpoint}`],
      type: 'gauge',
    }))

    // å®é™…çš„ HTTP è¯·æ±‚å‘é€é€»è¾‘
  }

  private async sendToSlack(anomalies: any[]) {
    if (anomalies.length === 0) return

    const message = {
      text: `âš ï¸ æ£€æµ‹åˆ° ${anomalies.length} ä¸ªæ€§èƒ½å¼‚å¸¸`,
      blocks: anomalies.map(anomaly => ({
        type: 'section',
        text: {
          type: 'mrkdwn',
          text: `*${anomaly.endpoint}*\nå¹³å‡å“åº”æ—¶é—´: ${anomaly.avgDuration}ms\né”™è¯¯ç‡: ${(anomaly.errorRate * 100).toFixed(2)}%`,
        },
      })),
    }

    // å‘é€åˆ° Slack webhook
  }

  private async updateHealthStatus(summaryData: any[]) {
    const overallHealth = this.calculateOverallHealth(summaryData)

    // æ›´æ–°å¥åº·çŠ¶æ€åˆ° KV å­˜å‚¨
    // await env.HEALTH_STATUS.put('overall_health', JSON.stringify(overallHealth))
  }

  private calculateOverallHealth(summaryData: any[]): {
    status: string
    score: number
    issues: string[]
  } {
    let score = 100
    const issues: string[] = []

    for (const data of summaryData) {
      if (data.avgDuration > 1000) {
        score -= 10
        issues.push(`${data.endpoint} å“åº”æ—¶é—´è¿‡é•¿`)
      }
      if (data.errorRate > 0.01) {
        score -= 20
        issues.push(`${data.endpoint} é”™è¯¯ç‡åé«˜`)
      }
    }

    const status =
      score > 90 ? 'healthy' : score > 70 ? 'degraded' : 'unhealthy'
    return { status, score, issues }
  }
}

// å…¨å±€åˆ†æå¼•æ“å®ä¾‹
export const analyticsEngine = new CloudflareAnalyticsEngine('vue_blog_metrics')
```

#### é«˜çº§æ€§èƒ½ä¸­é—´ä»¶

```typescript
// src/middleware/performance-advanced.ts
import { Context, Next } from 'hono'
import { analyticsEngine } from '../utils/analytics-engine'

export interface RequestContext extends Context {
  startTime: number
  metrics: {
    dbQueries: Array<{
      sql: string
      duration: number
      rowsAffected: number
    }>
    cacheHits: number
    cacheMisses: number
    computeOperations: Array<{
      operation: string
      duration: number
    }>
  }
}

export const advancedPerformanceMiddleware = async (c: Context, next: Next) => {
  const startTime = performance.now()
  const requestId = c.req.header('cf-ray') || generateRequestId()

  // å¢å¼ºä¸Šä¸‹æ–‡ï¼Œæ·»åŠ æ€§èƒ½ç›‘æ§èƒ½åŠ›
  const enhancedContext = c as RequestContext
  enhancedContext.startTime = startTime
  enhancedContext.metrics = {
    dbQueries: [],
    cacheHits: 0,
    cacheMisses: 0,
    computeOperations: [],
  }

  // åŒ…è£…æ•°æ®åº“å¯¹è±¡ä»¥ç›‘æ§æŸ¥è¯¢æ€§èƒ½
  if (c.env.DB) {
    c.env.DB = createDBProxy(c.env.DB, enhancedContext.metrics)
  }

  // åŒ…è£…ç¼“å­˜å¯¹è±¡ä»¥ç›‘æ§ç¼“å­˜æ€§èƒ½
  if (c.env.KV_CACHE) {
    c.env.KV_CACHE = createCacheProxy(c.env.KV_CACHE, enhancedContext.metrics)
  }

  // æ·»åŠ è®¡ç®—æ€§èƒ½ç›‘æ§å‡½æ•°
  enhancedContext.measureCompute = (operation: string, fn: () => any) => {
    const start = performance.now()
    const result = fn()
    const duration = performance.now() - start

    enhancedContext.metrics.computeOperations.push({
      operation,
      duration,
    })

    return result
  }

  let error: any = null

  try {
    await next()
  } catch (err) {
    error = err
    throw err
  } finally {
    const totalDuration = performance.now() - startTime

    // è®¡ç®—å„éƒ¨åˆ†è€—æ—¶
    const dbQueryTime = enhancedContext.metrics.dbQueries.reduce(
      (sum, query) => sum + query.duration,
      0,
    )
    const computeTime = enhancedContext.metrics.computeOperations.reduce(
      (sum, op) => sum + op.duration,
      0,
    )
    const networkTime = totalDuration - dbQueryTime - computeTime

    // æ”¶é›†å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡
    const metrics = {
      requestId,
      endpoint: new URL(c.req.url).pathname,
      method: c.req.method,
      status: c.res.status,
      duration: totalDuration,
      dbQueryTime,
      computeTime,
      networkTime,
      userAgent: c.req.header('user-agent') || 'unknown',
      country: c.req.header('cf-ipcountry') || 'unknown',
      colo: c.req.header('cf-colo') || 'unknown',

      // è¯¦ç»†æŒ‡æ ‡
      dbQueryCount: enhancedContext.metrics.dbQueries.length,
      cacheHitRate:
        enhancedContext.metrics.cacheHits /
        (enhancedContext.metrics.cacheHits +
          enhancedContext.metrics.cacheMisses),

      // é”™è¯¯ä¿¡æ¯
      errorCode: error?.code,
      errorMessage: error?.message,
    }

    // å¼‚æ­¥å‘é€ç›‘æ§æ•°æ®
    c.executionCtx?.waitUntil(analyticsEngine.track(metrics, c.env))

    // è®¾ç½®å“åº”å¤´
    c.header('X-Request-ID', requestId)
    c.header('X-Response-Time', `${totalDuration.toFixed(2)}ms`)
    c.header('X-DB-Query-Time', `${dbQueryTime.toFixed(2)}ms`)
    c.header('X-Cache-Hit-Rate', `${(metrics.cacheHitRate * 100).toFixed(1)}%`)

    // æ€§èƒ½é¢„è­¦
    if (totalDuration > 5000) {
      console.warn(
        `Slow request detected: ${c.req.method} ${c.req.url} took ${totalDuration}ms`,
      )
    }

    if (metrics.cacheHitRate < 0.8) {
      console.warn(
        `Low cache hit rate: ${(metrics.cacheHitRate * 100).toFixed(1)}% for ${c.req.url}`,
      )
    }
  }
}

function createDBProxy(
  originalDB: D1Database,
  metrics: RequestContext['metrics'],
) {
  return new Proxy(originalDB, {
    get(target, prop) {
      if (prop === 'prepare') {
        return (sql: string) => {
          const statement = target.prepare(sql)
          return new Proxy(statement, {
            get(stmtTarget, stmtProp) {
              if (['first', 'all', 'run'].includes(stmtProp as string)) {
                return async (...args: any[]) => {
                  const queryStart = performance.now()
                  const result = await stmtTarget[
                    stmtProp as keyof typeof stmtTarget
                  ](...args)
                  const queryDuration = performance.now() - queryStart

                  metrics.dbQueries.push({
                    sql:
                      sql.substring(0, 100) + (sql.length > 100 ? '...' : ''),
                    duration: queryDuration,
                    rowsAffected: result?.meta?.changes || 0,
                  })

                  return result
                }
              }
              return stmtTarget[stmtProp as keyof typeof stmtTarget]
            },
          })
        }
      }
      return target[prop as keyof typeof target]
    },
  })
}

function createCacheProxy(
  originalKV: KVNamespace,
  metrics: RequestContext['metrics'],
) {
  return new Proxy(originalKV, {
    get(target, prop) {
      if (prop === 'get') {
        return async (key: string, options?: any) => {
          const result = await target.get(key, options)
          if (result !== null) {
            metrics.cacheHits++
          } else {
            metrics.cacheMisses++
          }
          return result
        }
      }
      return target[prop as keyof typeof target]
    },
  })
}

function generateRequestId(): string {
  return (
    Math.random().toString(36).substring(2, 15) +
    Math.random().toString(36).substring(2, 15)
  )
}
```

### æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

#### æ™ºèƒ½ç´¢å¼•ä¼˜åŒ–å™¨

```typescript
// src/utils/database-optimizer.ts
export interface QueryAnalysis {
  sql: string
  executionTime: number
  rowsExamined: number
  rowsReturned: number
  useIndex: boolean
  suggestedIndexes: string[]
  optimizationScore: number
}

export class DatabaseOptimizer {
  private queryHistory: Map<string, QueryAnalysis[]> = new Map()
  private slowQueryThreshold = 100 // 100ms

  async analyzeQuery(
    db: D1Database,
    sql: string,
    params: any[],
  ): Promise<QueryAnalysis> {
    const start = performance.now()

    // æ‰§è¡ŒæŸ¥è¯¢è®¡åˆ’åˆ†æ
    const explainResult = await db
      .prepare(`EXPLAIN QUERY PLAN ${sql}`)
      .bind(...params)
      .all()

    // æ‰§è¡Œå®é™…æŸ¥è¯¢
    const actualResult = await db
      .prepare(sql)
      .bind(...params)
      .all()

    const executionTime = performance.now() - start

    // åˆ†ææŸ¥è¯¢è®¡åˆ’
    const analysis = this.parseExplainResult(explainResult.results)

    const queryAnalysis: QueryAnalysis = {
      sql,
      executionTime,
      rowsExamined: analysis.rowsExamined,
      rowsReturned: actualResult.results.length,
      useIndex: analysis.useIndex,
      suggestedIndexes: this.suggestIndexes(sql, analysis),
      optimizationScore: this.calculateOptimizationScore(
        analysis,
        executionTime,
      ),
    }

    // è®°å½•æŸ¥è¯¢å†å²
    const normalizedSQL = this.normalizeSQL(sql)
    if (!this.queryHistory.has(normalizedSQL)) {
      this.queryHistory.set(normalizedSQL, [])
    }
    this.queryHistory.get(normalizedSQL)!.push(queryAnalysis)

    return queryAnalysis
  }

  private parseExplainResult(explainResults: any[]): {
    rowsExamined: number
    useIndex: boolean
    scanType: string
  } {
    let rowsExamined = 0
    let useIndex = false
    let scanType = 'UNKNOWN'

    for (const row of explainResults) {
      const detail = row.detail || ''

      // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç´¢å¼•
      if (
        detail.includes('USING INDEX') ||
        detail.includes('USING COVERING INDEX')
      ) {
        useIndex = true
      }

      // ä¼°ç®—æ‰«æè¡Œæ•°
      if (detail.includes('SCAN')) {
        if (detail.includes('TABLE')) {
          scanType = 'FULL_TABLE_SCAN'
          rowsExamined = 10000 // ä¼°ç®—å€¼
        } else if (detail.includes('INDEX')) {
          scanType = 'INDEX_SCAN'
          rowsExamined = 100 // ä¼°ç®—å€¼
        }
      }
    }

    return { rowsExamined, useIndex, scanType }
  }

  private suggestIndexes(sql: string, analysis: any): string[] {
    const suggestions: string[] = []

    // ç®€åŒ–çš„ç´¢å¼•å»ºè®®é€»è¾‘
    const whereMatch = sql.match(
      /WHERE\s+(.+?)(?:\s+ORDER\s+BY|\s+GROUP\s+BY|\s+LIMIT|$)/i,
    )
    if (whereMatch) {
      const whereClause = whereMatch[1]

      // æ£€æŸ¥ç­‰å€¼æŸ¥è¯¢åˆ—
      const equalityColumns = whereClause.match(/(\w+)\s*=\s*/g)
      if (equalityColumns) {
        equalityColumns.forEach(col => {
          const columnName = col.replace(/\s*=\s*$/, '')
          suggestions.push(
            `CREATE INDEX IF NOT EXISTS idx_${columnName} ON table_name (${columnName})`,
          )
        })
      }

      // æ£€æŸ¥èŒƒå›´æŸ¥è¯¢åˆ—
      const rangeColumns = whereClause.match(/(\w+)\s*[<>]/g)
      if (rangeColumns) {
        rangeColumns.forEach(col => {
          const columnName = col.replace(/\s*[<>].*$/, '')
          suggestions.push(
            `CREATE INDEX IF NOT EXISTS idx_${columnName}_range ON table_name (${columnName})`,
          )
        })
      }
    }

    // æ£€æŸ¥ ORDER BY åˆ—
    const orderMatch = sql.match(/ORDER\s+BY\s+(.+?)(?:\s+LIMIT|$)/i)
    if (orderMatch) {
      const orderColumn = orderMatch[1].split(',')[0].trim()
      suggestions.push(
        `CREATE INDEX IF NOT EXISTS idx_${orderColumn}_sort ON table_name (${orderColumn})`,
      )
    }

    return suggestions
  }

  private calculateOptimizationScore(
    analysis: any,
    executionTime: number,
  ): number {
    let score = 100

    // æ‰§è¡Œæ—¶é—´æ‰£åˆ†
    if (executionTime > this.slowQueryThreshold) {
      score -= Math.min(50, (executionTime - this.slowQueryThreshold) / 10)
    }

    // æœªä½¿ç”¨ç´¢å¼•æ‰£åˆ†
    if (!analysis.useIndex) {
      score -= 30
    }

    // æ‰«æè¡Œæ•°è¿‡å¤šæ‰£åˆ†
    if (analysis.rowsExamined > 1000) {
      score -= 20
    }

    return Math.max(0, score)
  }

  private normalizeSQL(sql: string): string {
    // æ ‡å‡†åŒ– SQL ä»¥ä¾¿åˆ†ç»„ç›¸ä¼¼æŸ¥è¯¢
    return sql
      .replace(/\s+/g, ' ') // å‹ç¼©ç©ºæ ¼
      .replace(/=\s*[?$]\d*/g, '= ?') // æ ‡å‡†åŒ–å‚æ•°å ä½ç¬¦
      .replace(/IN\s*\([^)]+\)/gi, 'IN (?)') // æ ‡å‡†åŒ– IN å­å¥
      .toLowerCase()
      .trim()
  }

  async generateOptimizationReport(): Promise<{
    slowQueries: QueryAnalysis[]
    indexSuggestions: string[]
    performanceTrends: any[]
  }> {
    const slowQueries: QueryAnalysis[] = []
    const allIndexSuggestions = new Set<string>()
    const performanceTrends: any[] = []

    // åˆ†ææ‰€æœ‰æŸ¥è¯¢å†å²
    for (const [normalizedSQL, queries] of this.queryHistory.entries()) {
      const recentQueries = queries.slice(-10) // æœ€è¿‘10æ¬¡æŸ¥è¯¢
      const avgExecutionTime =
        recentQueries.reduce((sum, q) => sum + q.executionTime, 0) /
        recentQueries.length

      if (avgExecutionTime > this.slowQueryThreshold) {
        const worstQuery = recentQueries.sort(
          (a, b) => b.executionTime - a.executionTime,
        )[0]
        slowQueries.push(worstQuery)

        // æ”¶é›†ç´¢å¼•å»ºè®®
        worstQuery.suggestedIndexes.forEach(idx => allIndexSuggestions.add(idx))
      }

      // ç”Ÿæˆæ€§èƒ½è¶‹åŠ¿æ•°æ®
      if (queries.length >= 5) {
        const trend = this.calculatePerformanceTrend(queries)
        performanceTrends.push({
          sql: normalizedSQL,
          trend,
          currentAvg: avgExecutionTime,
          queryCount: queries.length,
        })
      }
    }

    return {
      slowQueries: slowQueries.sort(
        (a, b) => b.executionTime - a.executionTime,
      ),
      indexSuggestions: Array.from(allIndexSuggestions),
      performanceTrends,
    }
  }

  private calculatePerformanceTrend(
    queries: QueryAnalysis[],
  ): 'improving' | 'degrading' | 'stable' {
    if (queries.length < 5) return 'stable'

    const recentHalf = queries.slice(-Math.floor(queries.length / 2))
    const earlierHalf = queries.slice(0, Math.floor(queries.length / 2))

    const recentAvg =
      recentHalf.reduce((sum, q) => sum + q.executionTime, 0) /
      recentHalf.length
    const earlierAvg =
      earlierHalf.reduce((sum, q) => sum + q.executionTime, 0) /
      earlierHalf.length

    const changePercent = (recentAvg - earlierAvg) / earlierAvg

    if (changePercent > 0.2) return 'degrading'
    if (changePercent < -0.2) return 'improving'
    return 'stable'
  }
}

// å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
export const dbOptimizer = new DatabaseOptimizer()
```

#### è‡ªåŠ¨åŒ–ç¼“å­˜é¢„çƒ­ç³»ç»Ÿ

```typescript
// src/utils/cache-warmer.ts
export interface CacheWarmupRule {
  key: string
  generator: () => Promise<any>
  ttl: number
  refreshInterval: number
  dependencies: string[]
  priority: 'high' | 'medium' | 'low'
}

export class CacheWarmer {
  private rules: Map<string, CacheWarmupRule> = new Map()
  private warmupInProgress = new Set<string>()

  registerRule(rule: CacheWarmupRule) {
    this.rules.set(rule.key, rule)
  }

  async warmupCache(
    env: any,
    keys?: string[],
  ): Promise<{
    success: string[]
    failed: string[]
    skipped: string[]
  }> {
    const success: string[] = []
    const failed: string[] = []
    const skipped: string[] = []

    const rulesToWarmup = keys
      ? keys.map(key => this.rules.get(key)).filter(Boolean)
      : Array.from(this.rules.values())

    // æŒ‰ä¼˜å…ˆçº§æ’åº
    const sortedRules = rulesToWarmup.sort((a, b) => {
      const priorityOrder = { high: 3, medium: 2, low: 1 }
      return priorityOrder[b!.priority] - priorityOrder[a!.priority]
    })

    // å¹¶å‘æ‰§è¡Œï¼ˆé™åˆ¶å¹¶å‘æ•°ï¼‰
    const concurrencyLimit = 5
    const chunks = this.chunkArray(sortedRules, concurrencyLimit)

    for (const chunk of chunks) {
      await Promise.all(
        chunk.map(async rule => {
          if (!rule) return

          try {
            if (this.warmupInProgress.has(rule.key)) {
              skipped.push(rule.key)
              return
            }

            this.warmupInProgress.add(rule.key)

            // æ£€æŸ¥ä¾èµ–
            const dependenciesMet = await this.checkDependencies(
              rule.dependencies,
              env,
            )
            if (!dependenciesMet) {
              skipped.push(rule.key)
              return
            }

            // ç”Ÿæˆç¼“å­˜æ•°æ®
            const data = await rule.generator()

            // å­˜å‚¨åˆ°ç¼“å­˜
            await env.KV_CACHE.put(rule.key, JSON.stringify(data), {
              expirationTtl: rule.ttl,
            })

            success.push(rule.key)
          } catch (error) {
            console.error(`Cache warmup failed for ${rule.key}:`, error)
            failed.push(rule.key)
          } finally {
            this.warmupInProgress.delete(rule.key)
          }
        }),
      )
    }

    return { success, failed, skipped }
  }

  private async checkDependencies(
    dependencies: string[],
    env: any,
  ): Promise<boolean> {
    if (dependencies.length === 0) return true

    const dependencyChecks = await Promise.all(
      dependencies.map(async dep => {
        const value = await env.KV_CACHE.get(dep)
        return value !== null
      }),
    )

    return dependencyChecks.every(Boolean)
  }

  private chunkArray<T>(array: T[], chunkSize: number): T[][] {
    const chunks: T[][] = []
    for (let i = 0; i < array.length; i += chunkSize) {
      chunks.push(array.slice(i, i + chunkSize))
    }
    return chunks
  }

  async schedulePeriodicWarmup(env: any) {
    // è¿™ä¸ªå‡½æ•°ä¼šè¢« Cron è§¦å‘å™¨è°ƒç”¨
    console.log('Starting periodic cache warmup...')

    const result = await this.warmupCache(env)

    console.log(`Cache warmup completed:`, {
      success: result.success.length,
      failed: result.failed.length,
      skipped: result.skipped.length,
    })

    // å‘é€é€šçŸ¥åˆ°ç›‘æ§ç³»ç»Ÿ
    if (result.failed.length > 0) {
      await this.notifyWarmupFailures(result.failed, env)
    }

    return result
  }

  private async notifyWarmupFailures(failedKeys: string[], env: any) {
    const message = {
      text: 'âš ï¸ ç¼“å­˜é¢„çƒ­éƒ¨åˆ†å¤±è´¥',
      details: {
        failedKeys,
        timestamp: new Date().toISOString(),
        environment: env.ENVIRONMENT || 'unknown',
      },
    }

    // å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
    await Promise.allSettled([
      this.sendToSlack(message),
      this.recordToAnalytics(message, env),
    ])
  }

  private async sendToSlack(message: any) {
    // Slack é€šçŸ¥å®ç°
  }

  private async recordToAnalytics(message: any, env: any) {
    // è®°å½•åˆ°åˆ†æç³»ç»Ÿ
  }
}

// é¢„å®šä¹‰çš„ç¼“å­˜é¢„çƒ­è§„åˆ™
export const setupCacheWarmupRules = (warmer: CacheWarmer, db: D1Database) => {
  // çƒ­é—¨æ–‡ç« åˆ—è¡¨
  warmer.registerRule({
    key: 'popular_articles',
    generator: async () => {
      const result = await db
        .prepare(
          `
        SELECT id, title, summary, view_count, like_count
        FROM articles 
        WHERE status = 'published'
        ORDER BY view_count DESC, like_count DESC
        LIMIT 20
      `,
        )
        .all()
      return result.results
    },
    ttl: 3600, // 1å°æ—¶
    refreshInterval: 1800, // 30åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡
    dependencies: [],
    priority: 'high',
  })

  // ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯
  warmer.registerRule({
    key: 'user_stats',
    generator: async () => {
      const [totalUsers, activeUsers, newUsers] = await Promise.all([
        db.prepare('SELECT COUNT(*) as count FROM users').first(),
        db
          .prepare(
            `
          SELECT COUNT(*) as count FROM users 
          WHERE updated_at > datetime('now', '-7 days')
        `,
          )
          .first(),
        db
          .prepare(
            `
          SELECT COUNT(*) as count FROM users 
          WHERE created_at > datetime('now', '-24 hours')
        `,
          )
          .first(),
      ])

      return {
        totalUsers: totalUsers.count,
        activeUsers: activeUsers.count,
        newUsers: newUsers.count,
        updatedAt: new Date().toISOString(),
      }
    },
    ttl: 1800, // 30åˆ†é’Ÿ
    refreshInterval: 900, // 15åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡
    dependencies: [],
    priority: 'medium',
  })

  // æ ‡ç­¾äº‘æ•°æ®
  warmer.registerRule({
    key: 'tag_cloud',
    generator: async () => {
      const result = await db
        .prepare(
          `
        SELECT tag, COUNT(*) as count
        FROM article_tags at
        JOIN articles a ON at.article_id = a.id
        WHERE a.status = 'published'
        GROUP BY tag
        ORDER BY count DESC
        LIMIT 50
      `,
        )
        .all()
      return result.results
    },
    ttl: 7200, // 2å°æ—¶
    refreshInterval: 3600, // 1å°æ—¶åˆ·æ–°ä¸€æ¬¡
    dependencies: [],
    priority: 'low',
  })
}

// å…¨å±€ç¼“å­˜é¢„çƒ­å™¨
export const cacheWarmer = new CacheWarmer()
```

### å‰ç«¯æ€§èƒ½ç›‘æ§

#### Core Web Vitals ç›‘æ§

```typescript
// src/utils/web-vitals-monitor.ts
export interface WebVitalsMetrics {
  // Core Web Vitals
  CLS: number // Cumulative Layout Shift
  FID: number // First Input Delay
  LCP: number // Largest Contentful Paint

  // å…¶ä»–é‡è¦æŒ‡æ ‡
  FCP: number // First Contentful Paint
  TTFB: number // Time to First Byte
  INP: number // Interaction to Next Paint

  // è‡ªå®šä¹‰æŒ‡æ ‡
  routeChangeTime: number
  apiResponseTime: number
  renderTime: number

  // ä¸Šä¸‹æ–‡ä¿¡æ¯
  url: string
  userAgent: string
  connectionType: string
  deviceMemory: number
  hardwareConcurrency: number
  timestamp: number
}

export class WebVitalsMonitor {
  private metrics: Partial<WebVitalsMetrics> = {}
  private observers: PerformanceObserver[] = []
  private reportEndpoint = '/api/analytics/web-vitals'
  private batchSize = 10
  private batchTimeout = 5000
  private metricsBuffer: WebVitalsMetrics[] = []
  private flushTimer?: number

  constructor() {
    this.initializeObservers()
    this.setupUnloadHandler()
  }

  private initializeObservers() {
    // ç›‘æ§ LCP
    if ('PerformanceObserver' in window) {
      const lcpObserver = new PerformanceObserver(entryList => {
        const entries = entryList.getEntries()
        const lastEntry = entries[entries.length - 1] as PerformanceEntry
        this.metrics.LCP = lastEntry.startTime
        this.scheduleReport()
      })

      try {
        lcpObserver.observe({
          type: 'largest-contentful-paint',
          buffered: true,
        })
        this.observers.push(lcpObserver)
      } catch (e) {
        console.warn('LCP observer not supported')
      }
    }

    // ç›‘æ§ FID
    if ('PerformanceObserver' in window) {
      const fidObserver = new PerformanceObserver(entryList => {
        const entries = entryList.getEntries()
        entries.forEach((entry: any) => {
          this.metrics.FID = entry.processingStart - entry.startTime
          this.scheduleReport()
        })
      })

      try {
        fidObserver.observe({ type: 'first-input', buffered: true })
        this.observers.push(fidObserver)
      } catch (e) {
        console.warn('FID observer not supported')
      }
    }

    // ç›‘æ§ CLS
    if ('PerformanceObserver' in window) {
      let clsValue = 0
      const clsObserver = new PerformanceObserver(entryList => {
        const entries = entryList.getEntries()
        entries.forEach((entry: any) => {
          if (!entry.hadRecentInput) {
            clsValue += entry.value
          }
        })
        this.metrics.CLS = clsValue
        this.scheduleReport()
      })

      try {
        clsObserver.observe({ type: 'layout-shift', buffered: true })
        this.observers.push(clsObserver)
      } catch (e) {
        console.warn('CLS observer not supported')
      }
    }

    // ç›‘æ§ FCP
    if ('PerformanceObserver' in window) {
      const fcpObserver = new PerformanceObserver(entryList => {
        const entries = entryList.getEntries()
        entries.forEach(entry => {
          if (entry.name === 'first-contentful-paint') {
            this.metrics.FCP = entry.startTime
            this.scheduleReport()
          }
        })
      })

      try {
        fcpObserver.observe({ type: 'paint', buffered: true })
        this.observers.push(fcpObserver)
      } catch (e) {
        console.warn('FCP observer not supported')
      }
    }

    // ç›‘æ§ TTFB
    if ('PerformanceObserver' in window) {
      const navigationObserver = new PerformanceObserver(entryList => {
        const entries = entryList.getEntries()
        entries.forEach((entry: any) => {
          this.metrics.TTFB = entry.responseStart - entry.requestStart
          this.scheduleReport()
        })
      })

      try {
        navigationObserver.observe({ type: 'navigation', buffered: true })
        this.observers.push(navigationObserver)
      } catch (e) {
        console.warn('Navigation observer not supported')
      }
    }
  }

  measureRouteChange(startTime: number, endTime: number) {
    this.metrics.routeChangeTime = endTime - startTime
    this.scheduleReport()
  }

  measureApiResponse(duration: number) {
    this.metrics.apiResponseTime = duration
    this.scheduleReport()
  }

  measureRender(duration: number) {
    this.metrics.renderTime = duration
    this.scheduleReport()
  }

  private scheduleReport() {
    // æ”¶é›†å®Œæ•´æŒ‡æ ‡åå†æŠ¥å‘Š
    const requiredMetrics = ['LCP', 'FID', 'CLS', 'FCP', 'TTFB']
    const hasAllMetrics = requiredMetrics.every(
      metric => this.metrics[metric as keyof WebVitalsMetrics] !== undefined,
    )

    if (hasAllMetrics) {
      this.reportMetrics()
    }
  }

  private reportMetrics() {
    const completeMetrics: WebVitalsMetrics = {
      ...this.metrics,
      url: window.location.href,
      userAgent: navigator.userAgent,
      connectionType: this.getConnectionType(),
      deviceMemory: this.getDeviceMemory(),
      hardwareConcurrency: navigator.hardwareConcurrency || 1,
      timestamp: Date.now(),
    } as WebVitalsMetrics

    this.addToBatch(completeMetrics)
    this.resetMetrics()
  }

  private addToBatch(metrics: WebVitalsMetrics) {
    this.metricsBuffer.push(metrics)

    if (this.metricsBuffer.length >= this.batchSize) {
      this.flushBatch()
    } else if (!this.flushTimer) {
      this.flushTimer = window.setTimeout(
        () => this.flushBatch(),
        this.batchTimeout,
      )
    }
  }

  private async flushBatch() {
    if (this.metricsBuffer.length === 0) return

    const batch = [...this.metricsBuffer]
    this.metricsBuffer = []

    if (this.flushTimer) {
      clearTimeout(this.flushTimer)
      this.flushTimer = undefined
    }

    try {
      await fetch(this.reportEndpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ metrics: batch }),
      })
    } catch (error) {
      console.warn('Failed to report web vitals:', error)
      // å¤±è´¥çš„æŒ‡æ ‡é‡æ–°åŠ å…¥ç¼“å†²åŒº
      this.metricsBuffer.unshift(...batch)
    }
  }

  private getConnectionType(): string {
    const connection =
      (navigator as any).connection ||
      (navigator as any).mozConnection ||
      (navigator as any).webkitConnection

    return connection?.effectiveType || 'unknown'
  }

  private getDeviceMemory(): number {
    return (navigator as any).deviceMemory || 4
  }

  private resetMetrics() {
    this.metrics = {}
  }

  private setupUnloadHandler() {
    // åœ¨é¡µé¢å¸è½½å‰å‘é€å‰©ä½™æŒ‡æ ‡
    const handleUnload = () => {
      if (this.metricsBuffer.length > 0) {
        if ('sendBeacon' in navigator) {
          navigator.sendBeacon(
            this.reportEndpoint,
            JSON.stringify({ metrics: this.metricsBuffer }),
          )
        }
      }
    }

    window.addEventListener('beforeunload', handleUnload)
    window.addEventListener('pagehide', handleUnload)
  }

  destroy() {
    this.observers.forEach(observer => observer.disconnect())
    this.observers = []

    if (this.flushTimer) {
      clearTimeout(this.flushTimer)
    }
  }
}

// é›†æˆåˆ° Vue åº”ç”¨
export const setupWebVitalsMonitoring = (app: any) => {
  const monitor = new WebVitalsMonitor()

  // ç›‘æ§è·¯ç”±å˜åŒ–
  const router = app.config.globalProperties.$router
  if (router) {
    router.beforeEach((to: any, from: any, next: any) => {
      const startTime = performance.now()

      router.afterEach(() => {
        const endTime = performance.now()
        monitor.measureRouteChange(startTime, endTime)
      })

      next()
    })
  }

  // ç›‘æ§ API è¯·æ±‚
  const originalFetch = window.fetch
  window.fetch = async (...args) => {
    const startTime = performance.now()

    try {
      const response = await originalFetch(...args)
      const endTime = performance.now()
      monitor.measureApiResponse(endTime - startTime)
      return response
    } catch (error) {
      const endTime = performance.now()
      monitor.measureApiResponse(endTime - startTime)
      throw error
    }
  }

  return monitor
}

// å…¨å±€ç›‘æ§å®ä¾‹
export const webVitalsMonitor = new WebVitalsMonitor()
```

## ğŸ› ï¸ å®è·µæ“ä½œ

### æ­¥éª¤1ï¼šé…ç½® Cloudflare Analytics

```bash
# 1. åœ¨ Cloudflare Dashboard ä¸­å¯ç”¨ Analytics Engine
# 2. åˆ›å»ºæ•°æ®é›†
wrangler analytics-engine create vue_blog_metrics

# 3. æ›´æ–° wrangler.toml
cat >> wrangler.toml << EOF
[[analytics_engine_datasets]]
binding = "ANALYTICS_ENGINE"
dataset = "vue_blog_metrics"
EOF
```

### æ­¥éª¤2ï¼šéƒ¨ç½²ç›‘æ§ä¸­é—´ä»¶

```typescript
// src/index.ts - é›†æˆç›‘æ§ä¸­é—´ä»¶
import { advancedPerformanceMiddleware } from './middleware/performance-advanced'
import { analyticsEngine } from './utils/analytics-engine'

// åº”ç”¨ä¸­é—´ä»¶
app.use(advancedPerformanceMiddleware)

// æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/api/health/detailed', async c => {
  const optimizer = new DatabaseOptimizer()
  const report = await optimizer.generateOptimizationReport()

  return c.json({
    status: 'ok',
    timestamp: new Date().toISOString(),
    performance: {
      slowQueries: report.slowQueries.length,
      suggestedOptimizations: report.indexSuggestions.length,
      trends: report.performanceTrends,
    },
  })
})
```

### æ­¥éª¤3ï¼šè®¾ç½®è‡ªåŠ¨åŒ–ç›‘æ§å‘Šè­¦

```typescript
// scripts/setup-monitoring.ts
import { CacheWarmer, setupCacheWarmupRules } from '../src/utils/cache-warmer'

export async function setupMonitoring(env: any) {
  // è®¾ç½®ç¼“å­˜é¢„çƒ­
  const warmer = new CacheWarmer()
  setupCacheWarmupRules(warmer, env.DB)

  // æ‰§è¡Œåˆå§‹é¢„çƒ­
  console.log('Starting initial cache warmup...')
  const result = await warmer.warmupCache(env)
  console.log('Cache warmup result:', result)

  // è®¾ç½®å®šæœŸä»»åŠ¡ï¼ˆé€šè¿‡ Cron Triggersï¼‰
  return {
    warmer,
    scheduledTasks: [
      'cache-warmup', // æ¯15åˆ†é’Ÿ
      'performance-analysis', // æ¯å°æ—¶
      'health-check', // æ¯5åˆ†é’Ÿ
    ],
  }
}
```

### æ­¥éª¤4ï¼šé…ç½® Cron è§¦å‘å™¨

```toml
# wrangler.toml - æ·»åŠ å®šæ—¶ä»»åŠ¡
[[triggers]]
crons = ["*/15 * * * *"] # æ¯15åˆ†é’Ÿæ‰§è¡Œç¼“å­˜é¢„çƒ­

[[triggers]]
crons = ["0 * * * *"] # æ¯å°æ—¶æ‰§è¡Œæ€§èƒ½åˆ†æ

[[triggers]]
crons = ["*/5 * * * *"] # æ¯5åˆ†é’Ÿå¥åº·æ£€æŸ¥
```

```typescript
// src/scheduled.ts - å®šæ—¶ä»»åŠ¡å¤„ç†
export async function handleScheduled(
  event: ScheduledEvent,
  env: Env,
  ctx: ExecutionContext,
): Promise<Response> {
  switch (event.cron) {
    case '*/15 * * * *':
      // ç¼“å­˜é¢„çƒ­
      await cacheWarmer.schedulePeriodicWarmup(env)
      break

    case '0 * * * *':
      // æ€§èƒ½åˆ†æ
      const report = await dbOptimizer.generateOptimizationReport()
      if (report.slowQueries.length > 0) {
        await sendPerformanceAlert(report, env)
      }
      break

    case '*/5 * * * *':
      // å¥åº·æ£€æŸ¥
      await performHealthCheck(env)
      break
  }

  return new Response('OK')
}

async function sendPerformanceAlert(report: any, env: any) {
  const message = {
    text: `âš¡ æ€§èƒ½æŠ¥å‘Šï¼šå‘ç° ${report.slowQueries.length} ä¸ªæ…¢æŸ¥è¯¢`,
    details: report.slowQueries.slice(0, 5), // æ˜¾ç¤ºå‰5ä¸ª
  }

  // å‘é€å‘Šè­¦
  await fetch(env.SLACK_WEBHOOK_URL, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(message),
  })
}
```

## ğŸ” æ·±å…¥æ€è€ƒ

### æ€§èƒ½ç›‘æ§çš„å±‚æ¬¡åŒ–ç­–ç•¥

1. **å®æ—¶ç›‘æ§**ï¼šå…³é”®æŒ‡æ ‡çš„å®æ—¶è¿½è¸ªå’Œå‘Šè­¦
2. **è¶‹åŠ¿åˆ†æ**ï¼šé•¿æœŸæ€§èƒ½è¶‹åŠ¿çš„è¯†åˆ«å’Œé¢„æµ‹
3. **æ ¹å› åˆ†æ**ï¼šæ€§èƒ½é—®é¢˜çš„æ·±åº¦åˆ†æå’Œå®šä½
4. **é¢„é˜²æ€§ä¼˜åŒ–**ï¼šåŸºäºå†å²æ•°æ®çš„ä¸»åŠ¨ä¼˜åŒ–

### ç›‘æ§æ•°æ®çš„ä»·å€¼æŒ–æ˜

```typescript
// ç›‘æ§æ•°æ®åˆ†æç¤ºä¾‹
const performanceInsights = {
  // ç”¨æˆ·è¡Œä¸ºåˆ†æ
  userJourney: {
    bounceRate: 0.25, // è·³å‡ºç‡
    averageSessionTime: 180, // å¹³å‡ä¼šè¯æ—¶é•¿
    pageViewsPerSession: 3.5, // æ¯ä¼šè¯é¡µé¢æµè§ˆé‡
    conversionFunnels: {
      register: 0.12,
      login: 0.85,
      publish: 0.3,
    },
  },

  // æ€§èƒ½åŸºå‡†
  benchmarks: {
    loadTime: { target: 2000, current: 1850, trend: 'improving' },
    apiResponseTime: { target: 500, current: 320, trend: 'stable' },
    errorRate: { target: 0.01, current: 0.005, trend: 'improving' },
  },

  // ä¼˜åŒ–å»ºè®®
  recommendations: [
    {
      type: 'database',
      priority: 'high',
      description: 'ä¸º articles.author_id æ·»åŠ ç´¢å¼•',
      impact: 'é¢„è®¡å‡å°‘30%æŸ¥è¯¢æ—¶é—´',
    },
    {
      type: 'cache',
      priority: 'medium',
      description: 'å¢åŠ ç”¨æˆ·ä¸ªäººèµ„æ–™ç¼“å­˜',
      impact: 'å‡å°‘é‡å¤æ•°æ®åº“æŸ¥è¯¢',
    },
  ],
}
```

## â“ é‡åˆ°çš„é—®é¢˜

### é—®é¢˜ 1ï¼šç›‘æ§æ•°æ®é‡è¿‡å¤§å¯¼è‡´æˆæœ¬å¢åŠ 

**é—®é¢˜æè¿°**ï¼šå¤§é‡ç›‘æ§æ•°æ®å¯¼è‡´ Analytics Engine æˆæœ¬å¿«é€Ÿå¢é•¿  
**è§£å†³æ–¹æ¡ˆ**ï¼š

```typescript
// æ™ºèƒ½é‡‡æ ·ç­–ç•¥
const shouldSample = (metrics: PerformanceMetrics): boolean => {
  // æ€»æ˜¯è®°å½•é”™è¯¯å’Œæ…¢è¯·æ±‚
  if (metrics.status >= 400 || metrics.duration > 1000) {
    return true
  }

  // æ­£å¸¸è¯·æ±‚æŒ‰æ¯”ä¾‹é‡‡æ ·
  return Math.random() < 0.1 // 10% é‡‡æ ·ç‡
}
```

### é—®é¢˜ 2ï¼šç›‘æ§ç³»ç»Ÿæœ¬èº«å½±å“æ€§èƒ½

**é—®é¢˜æè¿°**ï¼šç›‘æ§ä»£ç å¢åŠ äº†è¯·æ±‚å»¶è¿Ÿ  
**è§£å†³æ–¹æ¡ˆ**ï¼š

- ä½¿ç”¨å¼‚æ­¥å¤„ç†é¿å…é˜»å¡ä¸»æµç¨‹
- æ‰¹é‡å‘é€ç›‘æ§æ•°æ®å‡å°‘ç½‘ç»œå¼€é”€
- åœ¨ Worker ä¸­ä½¿ç”¨ `executionCtx.waitUntil()`

### é—®é¢˜ 3ï¼šç›‘æ§å‘Šè­¦å™ªéŸ³è¿‡å¤š

**é—®é¢˜æè¿°**ï¼šè¿‡å¤šçš„å‘Šè­¦å¯¼è‡´é‡è¦é—®é¢˜è¢«å¿½ç•¥  
**è§£å†³æ–¹æ¡ˆ**ï¼š

- è®¾ç½®åˆç†çš„å‘Šè­¦é˜ˆå€¼å’Œå†·å´æ—¶é—´
- ä½¿ç”¨å‘Šè­¦ç­‰çº§å’Œåˆ†ç»„
- å®æ–½æ™ºèƒ½å‘Šè­¦å»é‡å’Œèšåˆ

## ğŸ’¡ ä¸ªäººå¿ƒå¾—

### ä»Šå¤©æœ€å¤§çš„æ”¶è·

å»ºç«‹äº†å®Œæ•´çš„æ€§èƒ½ç›‘æ§ä½“ç³»ï¼Œæ·±å…¥ç†è§£äº†å¦‚ä½•åœ¨è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸­å®ç°é«˜æ•ˆçš„æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–ã€‚

### æ€§èƒ½ç›‘æ§çš„æ ¸å¿ƒæ´å¯Ÿ

1. **æ•°æ®é©±åŠ¨**ï¼šåŸºäºçœŸå®æ•°æ®è€ŒéçŒœæµ‹è¿›è¡Œä¼˜åŒ–å†³ç­–
2. **å…¨é“¾è·¯ç›‘æ§**ï¼šä»ç”¨æˆ·ä½“éªŒåˆ°åŸºç¡€è®¾æ–½çš„å®Œæ•´ç›‘æ§
3. **ä¸»åŠ¨é¢„é˜²**ï¼šé€šè¿‡é¢„æµ‹æ€§åˆ†ææå‰å‘ç°é—®é¢˜
4. **æŒç»­æ”¹è¿›**ï¼šç›‘æ§-åˆ†æ-ä¼˜åŒ–çš„é—­ç¯å¾ªç¯

## ğŸ“‹ è¡ŒåŠ¨æ¸…å•

### ä»Šæ—¥å®Œæˆ

- [x] é…ç½® Cloudflare Analytics Engine æ•°æ®æ”¶é›†
- [x] å®ç°é«˜çº§æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶
- [x] å»ºç«‹æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–ç³»ç»Ÿ
- [x] è®¾ç½®å‰ç«¯ Core Web Vitals ç›‘æ§

### æ˜æ—¥é¢„ä¹ 

- [ ] äº†è§£é¡¹ç›®æ–‡æ¡£ç¼–å†™æœ€ä½³å®è·µ
- [ ] å‡†å¤‡æ¶æ„è¿ç§»æ€»ç»“æŠ¥å‘Š
- [ ] æ€è€ƒåç»­ä¼˜åŒ–å’Œæ‰©å±•è®¡åˆ’

## ğŸ”— æœ‰ç”¨é“¾æ¥

- [Cloudflare Analytics Engine](https://developers.cloudflare.com/analytics/analytics-engine/)
- [Core Web Vitals](https://web.dev/vitals/)
- [Performance Observer API](https://developer.mozilla.org/en-US/docs/Web/API/PerformanceObserver)
- [SQLite æ€§èƒ½ä¼˜åŒ–](https://www.sqlite.org/optoverview.html)

---

**ğŸ“ æ˜æ—¥é‡ç‚¹**ï¼šå®Œæˆé¡¹ç›®æ–‡æ¡£æ›´æ–°å’Œæ•´ä¸ª V2 æ¶æ„è¿ç§»çš„æ€»ç»“æ”¶å°¾å·¥ä½œã€‚
